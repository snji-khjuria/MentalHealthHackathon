{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gksKpyHDErp"
   },
   "source": [
    "# Generate multiple responses for 6k questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JoCFteg4DMV3",
    "outputId": "415d98dd-4c72-41e3-b71e-c8eadd0feeb0"
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLMu-xLhDPQ_"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key=''\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtEKn1N2ETkw",
    "outputId": "e8d031af-6482-478d-cdc2-72196d2533e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "df_question_answer = pd.read_csv(\"combined_counselchat.csv\")\n",
    "df_questions       = pd.read_csv(\"augmented_questions.csv\")\n",
    "\n",
    "df_question_answer.head()\n",
    "print(\"Total question answer pairs \", len(df_question_answer))\n",
    "print(\"total number of questions \", len(df_questions))\n",
    "all_questions = df_questions['question'].tolist()\n",
    "\n",
    "\n",
    "def generate_prompt(question, df_question_answer):\n",
    "  sampled_rows = df_question_answer.sample(n=3)\n",
    "  snippets = '\\n\\n'.join([f\"**Snippet {i+1}:**\\nClient: {row['question']}\\nTherapist: {row['answer']}\"\n",
    "                        for i, (_, row) in enumerate(sampled_rows.iterrows())])\n",
    "  prompt = f\"\"\"\n",
    "    Imagine you are a therapist responding to a person struggling with a mental health issue.\n",
    "    As a mental health therapist, you often engage in conversations similar to the following snippets:\n",
    "  {snippets}\n",
    "  Now, a new client asks: \"{question}\".\n",
    "  Please generate 10 responses as a mental health therapist.\n",
    "  Please provide the output in the following JSON format without response number:\n",
    "\n",
    "    \"responses\": [\n",
    "      \"Response 1\",\n",
    "      \"Response 2\",\n",
    "      \"Response 3\",\n",
    "      \"Response 4\",\n",
    "      \"Response 5\",\n",
    "      \"Response 6\",\n",
    "      \"Response 7\",\n",
    "      \"Response 8\",\n",
    "      \"Response 9\",\n",
    "      \"Response 10\"\n",
    "    ]\n",
    "\n",
    "  \"\"\"\n",
    "  return prompt.format(new_question=question, snippets=snippets)\n",
    "\n",
    "def generate_answers_from_prompt(client, question, answers):\n",
    "  prompt = generate_prompt(question, answers)\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    response_format= {\"type\": \"json_object\"},\n",
    "    messages =[   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\":prompt}\n",
    "                  ]\n",
    "    )\n",
    "  output = json.loads(response.choices[0].message.content)\n",
    "  generated_answers = set(output.get(\"responses\", []))\n",
    "  return generated_answers\n",
    "\n",
    "\n",
    "\n",
    "all_questions = df_questions['question'].values.tolist()\n",
    "all_questions = all_questions[:12]\n",
    "\n",
    "synthetic_answers_dict = {}\n",
    "count=0\n",
    "for q in all_questions:\n",
    "  count+=1\n",
    "  if count%10==0:\n",
    "    print(\"Count is \", count)\n",
    "  try:\n",
    "    generated_answers = generate_answers_from_prompt(client, q, df_question_answer)\n",
    "    synthetic_answers_dict[q] = generated_answers\n",
    "  except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "def create_df(synthetic_answers_dict):\n",
    "  rows = []\n",
    "  for question, answers in synthetic_answers_dict.items():\n",
    "    for answer in answers:\n",
    "        rows.append((question, answer))\n",
    "  df = pd.DataFrame(rows, columns=['question', 'answer'])\n",
    "  return df\n",
    "df_generated = create_df(synthetic_answers_dict)\n",
    "df_generated.to_excel(\"6k_questions_with_answers.xlsx\", index=None)\n",
    "print(\"length of generadted df is \", len(df_generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZn_-yDdOeo6"
   },
   "outputs": [],
   "source": [
    "df_generated.to_excel(\"questions_with_answers.xlsx\", index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "def generate_prompt(questions_list):\n",
    "  random_sample = random.sample(questions_list, 5)\n",
    "  sample_string = \"\\n\".join([f\"{i+1}. {question}\" for i, question in enumerate(random_sample)])\n",
    "  prompt=\"\"\"\n",
    "  Imagine you are someone struggling with a mental health issue and you're seeking help from a therapist.\n",
    "  Based on common concerns and difficulties people face, generate a list of 10-15 questions that someone in this situation might ask.\n",
    "  These questions should reflect a range of emotions, from seeking understanding and validation to asking for coping strategies and treatment options.\n",
    "  Here are some of the questions that might come to mind:\n",
    "  ```{}```\n",
    "  Please provide the output as a JSON array with each question listed as a separate item, without item numbers, and exclude any example questions given.\n",
    "  \"\"\"\n",
    "  return prompt.format(sample_string)\n",
    "\n",
    "\n",
    "def generate_questions(client, questions_list):\n",
    "  prompt = generate_prompt(questions_list)\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    response_format= {\"type\": \"json_object\"},\n",
    "    messages =[   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\":prompt}\n",
    "                  ]\n",
    "    )\n",
    "  output = json.loads(response.choices[0].message.content)\n",
    "  generated_questions = set(output.get(\"questions\", []))\n",
    "  return generated_questions\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"combined_counselchat.csv\")\n",
    "\n",
    "questions_list = list(set(df['question']))\n",
    "questions_db = set(questions_list)\n",
    "initial_length = len(questions_db)\n",
    "new_questions_db = set()\n",
    "to_be_generated = 2000\n",
    "while len(questions_db)<initial_length+to_be_generated:\n",
    "  new_questions = generate_questions(client, questions_list)\n",
    "  questions_db.update(new_questions)\n",
    "  new_questions_db.update(new_questions)\n",
    "  print(\"Questions database now...\", len(questions_db))\n",
    "\n",
    "new_questions_list = list(new_questions_db)\n",
    "old_questions = set(df['question'])\n",
    "print(\"Total old questions \", len(old_questions))\n",
    "print(\"Total new questions \", len(new_questions_db))\n",
    "print(\"Total common questions \", old_questions.intersection(new_questions_db))\n",
    "\n",
    "# Create a DataFrame with a single column named 'question'\n",
    "df_questions = pd.DataFrame(new_questions_list, columns=['question'])\n",
    "\n",
    "df_questions.to_csv(\"augmented_questions.csv\", index=None)\n",
    "print(\"Length of df was \", len(df_questions))\n",
    "print(\"Questions generated successfully.\")\n",
    "# Print the DataFrame\n",
    "# print(df_questions)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
